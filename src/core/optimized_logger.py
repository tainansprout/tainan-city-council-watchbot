"""
é«˜æ•ˆèƒ½æ—¥èªŒç³»çµ±
åŒ…å«ç•°æ­¥è™•ç†ã€é ç·¨è­¯æ­£å‰‡è¡¨é”å¼æ•æ„Ÿè³‡æ–™éæ¿¾å’Œå„ªåŒ–çš„æ ¼å¼åŒ–å™¨
"""

import logging
import json
import re
import threading
import queue
import time
import copy
from typing import Dict, Any, Optional, Pattern, List
from datetime import datetime
from .logger import get_logger

# å–å¾—åŸºç¤ logger ç”¨æ–¼è‡ªèº«çš„æ—¥èªŒè¨˜éŒ„
base_logger = get_logger(__name__)


class OptimizedSensitiveDataFilter:
    """å„ªåŒ–çš„æ•æ„Ÿè³‡æ–™éæ¿¾å™¨"""
    
    # ğŸ”¥ é—œéµå„ªåŒ–ï¼šé ç·¨è­¯æ­£å‰‡è¡¨é”å¼
    _COMPILED_PATTERNS: List[Pattern] = [
        re.compile(r'(api_key["\']?\s*[:=]\s*["\']?)([^"\'>\s]+)', re.IGNORECASE),
        re.compile(r'(token["\']?\s*[:=]\s*["\']?)([^"\'>\s]+)', re.IGNORECASE),
        re.compile(r'(password["\']?\s*[:=]\s*["\']?)([^"\'>\s]+)', re.IGNORECASE),
        re.compile(r'(secret["\']?\s*[:=]\s*["\']?)([^"\'>\s]+)', re.IGNORECASE),
        re.compile(r'(Bearer\s+)([A-Za-z0-9\-_]+)', re.IGNORECASE),
        re.compile(r'(Authorization:\s*Bearer\s+)([A-Za-z0-9\-_]+)', re.IGNORECASE),
        # ä¿¡ç”¨å¡è™Ÿç¢¼
        re.compile(r'\b(?:\d{4}[-\s]?){3}\d{4}\b'),
        # é›»è©±è™Ÿç¢¼
        re.compile(r'\b09\d{8}\b'),
        # Email éƒ¨åˆ†é®è”½
        re.compile(r'([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'),
    ]
    
    # ğŸ”¥ æ€§èƒ½å„ªåŒ–ï¼šå¿«å–å¸¸è¦‹çš„æ¸…ç†çµæœ
    _cache: Dict[str, str] = {}
    _cache_lock = threading.Lock()
    _max_cache_size = 500  # è¼ƒå°çš„å¿«å–é¿å…è¨˜æ†¶é«”éåº¦ä½¿ç”¨
    
    @classmethod
    def sanitize_fast(cls, text: str) -> str:
        """
        å¿«é€Ÿæ•æ„Ÿè³‡æ–™æ¸…ç†
        
        Args:
            text: è¦æ¸…ç†çš„æ–‡æœ¬
            
        Returns:
            æ¸…ç†å¾Œçš„æ–‡æœ¬
        """
        if not text or not isinstance(text, str):
            return str(text)
        
        # ğŸ”¥ å¿«å–æª¢æŸ¥ï¼ˆåªå¿«å–çŸ­æ–‡æœ¬ï¼‰
        if len(text) < 500:
            with cls._cache_lock:
                if text in cls._cache:
                    return cls._cache[text]
        
        # é•·åº¦é™åˆ¶ï¼Œé¿å…è™•ç†è¶…å¤§å­—ä¸²
        if len(text) > 10000:
            text = text[:10000] + "...[truncated]"
        
        # ä½¿ç”¨é ç·¨è­¯æ­£å‰‡å¿«é€Ÿè™•ç†
        sanitized = text
        for pattern in cls._COMPILED_PATTERNS:
            if pattern.pattern.startswith('([a-zA-Z0-9._%+-]+)@'):  # Email ç‰¹æ®Šè™•ç†
                sanitized = pattern.sub(r'\1***@\2', sanitized)
            else:
                sanitized = pattern.sub(r'\1***', sanitized)
        
        # ğŸ”¥ çµæœå¿«å–ï¼ˆæ§åˆ¶å¿«å–å¤§å°ï¼‰
        if len(text) < 500:
            with cls._cache_lock:
                if len(cls._cache) >= cls._max_cache_size:
                    # ç°¡å–®çš„ LRUï¼šæ¸…é™¤ä¸€åŠæœ€èˆŠçš„é …ç›®
                    items = list(cls._cache.items())
                    cls._cache = dict(items[len(items)//2:])
                cls._cache[text] = sanitized
        
        return sanitized
    
    @classmethod
    def get_cache_stats(cls) -> Dict[str, int]:
        """å–å¾—å¿«å–çµ±è¨ˆè³‡è¨Š"""
        with cls._cache_lock:
            return {
                'cache_size': len(cls._cache),
                'max_cache_size': cls._max_cache_size,
                'cache_usage_percent': int((len(cls._cache) / cls._max_cache_size) * 100)
            }
    
    @classmethod
    def clear_cache(cls):
        """æ¸…ç©ºå¿«å–"""
        with cls._cache_lock:
            cls._cache.clear()


class HighPerformanceFormatter(logging.Formatter):
    """é«˜æ•ˆèƒ½æ—¥èªŒæ ¼å¼åŒ–å™¨"""
    
    def __init__(self, enable_json: bool = False, enable_colors: bool = True):
        super().__init__()
        self.enable_json = enable_json
        self.enable_colors = enable_colors
        
        # ğŸ”¥ é å»ºç«‹é¡è‰²æ˜ å°„ï¼Œé¿å…é‡è¤‡è¨ˆç®—
        if enable_colors:
            self.color_map = {
                'DEBUG': '\033[36m',    # é’è‰²
                'INFO': '\033[32m',     # ç¶ è‰²  
                'WARNING': '\033[33m',  # é»ƒè‰²
                'ERROR': '\033[31m',    # ç´…è‰²
                'CRITICAL': '\033[35m', # ç´«è‰²
            }
            self.reset_color = '\033[0m'
        
        # ğŸ”¥ é å»ºç«‹æ™‚é–“æ ¼å¼ï¼Œé¿å…é‡è¤‡ strftime èª¿ç”¨
        self._last_time_cache = {}
        self._time_cache_lock = threading.Lock()
        
    def format(self, record: logging.LogRecord) -> str:
        """å„ªåŒ–çš„æ ¼å¼åŒ–æ–¹æ³•"""
        # ğŸ”¥ é¿å… copy.copyï¼Œç›´æ¥è™•ç†
        
        # å¿«é€Ÿæ•æ„Ÿè³‡æ–™æ¸…ç†
        try:
            message = OptimizedSensitiveDataFilter.sanitize_fast(record.getMessage())
        except Exception:
            # å¦‚æœæ¸…ç†å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹è¨Šæ¯ä½†è¨˜éŒ„è­¦å‘Š
            message = record.getMessage()
            base_logger.warning("æ•æ„Ÿè³‡æ–™æ¸…ç†å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹è¨Šæ¯")
        
        if self.enable_json:
            return self._format_json(record, message)
        else:
            return self._format_simple(record, message)
    
    def _format_json(self, record: logging.LogRecord, message: str) -> str:
        """JSON æ ¼å¼åŒ–"""
        log_data = {
            'time': self._get_formatted_time(),
            'level': record.levelname,
            'msg': message,
            'module': record.module,
        }
        
        # ğŸ”¥ åªæœ‰éŒ¯èª¤æ™‚æ‰åŠ å…¥é¡å¤–è³‡è¨Šï¼Œæ¸›å°‘ JSON å¤§å°
        if record.levelno >= logging.ERROR:
            log_data.update({
                'filename': record.filename,
                'lineno': record.lineno,
                'funcName': record.funcName,
            })
        
        # ğŸ”¥ ä½¿ç”¨æœ€ç·Šæ¹Šçš„ JSON æ ¼å¼
        return json.dumps(log_data, ensure_ascii=False, separators=(',', ':'))
    
    def _format_simple(self, record: logging.LogRecord, message: str) -> str:
        """ç°¡å–®æ ¼å¼åŒ–"""
        timestamp = self._get_formatted_time(simple=True)
        level = record.levelname
        
        if self.enable_colors and level in self.color_map:
            level_colored = f"{self.color_map[level]}{level}{self.reset_color}"
            return f"{timestamp} [{level_colored}] {message}"
        else:
            return f"{timestamp} [{level}] {message}"
    
    def _get_formatted_time(self, simple: bool = False) -> str:
        """å„ªåŒ–çš„æ™‚é–“æ ¼å¼åŒ–"""
        current_time = time.time()
        
        # ä½¿ç”¨ç°¡å–®çš„å¿«å–æ©Ÿåˆ¶ï¼Œå¿«å–åˆ°ç§’ç´šåˆ¥
        cache_key = int(current_time)
        format_key = 'simple' if simple else 'full'
        
        with self._time_cache_lock:
            if cache_key in self._last_time_cache:
                cached_times = self._last_time_cache[cache_key]
                if format_key in cached_times:
                    return cached_times[format_key]
            else:
                self._last_time_cache[cache_key] = {}
            
            # æ ¼å¼åŒ–æ™‚é–“
            dt = datetime.fromtimestamp(current_time)
            if simple:
                formatted = dt.strftime('%H:%M:%S')
            else:
                formatted = dt.isoformat()
            
            # å¿«å–çµæœ
            self._last_time_cache[cache_key][format_key] = formatted
            
            # æ¸…ç†èˆŠçš„å¿«å–é …ç›®ï¼ˆä¿ç•™æœ€è¿‘10ç§’ï¼‰
            cutoff = cache_key - 10
            old_keys = [k for k in self._last_time_cache.keys() if k < cutoff]
            for old_key in old_keys:
                del self._last_time_cache[old_key]
            
            return formatted


class AsyncLogHandler(logging.Handler):
    """ç•°æ­¥æ—¥èªŒè™•ç†å™¨ - é¿å… I/O é˜»å¡"""
    
    def __init__(self, target_handler: logging.Handler, queue_size: int = 1000):
        super().__init__()
        self.target_handler = target_handler
        self.log_queue = queue.Queue(maxsize=queue_size)
        self.worker_thread = None
        self.stop_event = threading.Event()
        self.dropped_logs = 0
        self._start_worker()
    
    def _start_worker(self):
        """å•Ÿå‹•èƒŒæ™¯å·¥ä½œåŸ·è¡Œç·’"""
        def worker():
            while not self.stop_event.is_set():
                try:
                    record = self.log_queue.get(timeout=1)
                    if record is None:  # åœæ­¢ä¿¡è™Ÿ
                        break
                    
                    # ç™¼é€åˆ°ç›®æ¨™è™•ç†å™¨
                    self.target_handler.emit(record)
                    self.log_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    # é¿å…æ—¥èªŒéŒ¯èª¤å½±éŸ¿ä¸»ç¨‹å¼
                    # ä½¿ç”¨ print é¿å…éè¿´æ—¥èªŒéŒ¯èª¤
                    print(f"ç•°æ­¥æ—¥èªŒè™•ç†éŒ¯èª¤: {e}")
        
        self.worker_thread = threading.Thread(target=worker, daemon=True, name='AsyncLogWorker')
        self.worker_thread.start()
    
    def emit(self, record: logging.LogRecord):
        """éé˜»å¡çš„æ—¥èªŒç™¼é€"""
        try:
            # ğŸ”¥ è¤‡è£½ record é¿å…ç·šç¨‹é–“æ•¸æ“šç«¶çˆ­
            record_copy = copy.copy(record)
            self.log_queue.put_nowait(record_copy)
        except queue.Full:
            # ä½‡åˆ—æ»¿æ™‚ä¸Ÿæ£„æ—¥èªŒï¼Œé¿å…é˜»å¡ä¸»ç¨‹å¼
            self.dropped_logs += 1
            # æ¯100å€‹ä¸Ÿæ£„çš„æ—¥èªŒå ±å‘Šä¸€æ¬¡
            if self.dropped_logs % 100 == 0:
                print(f"è­¦å‘Šï¼šå·²ä¸Ÿæ£„ {self.dropped_logs} æ¢æ—¥èªŒè¨Šæ¯")
    
    def get_stats(self) -> Dict[str, int]:
        """å–å¾—çµ±è¨ˆè³‡è¨Š"""
        return {
            'queue_size': self.log_queue.qsize(),
            'dropped_logs': self.dropped_logs,
            'worker_alive': self.worker_thread.is_alive() if self.worker_thread else False
        }
    
    def close(self):
        """é—œé–‰è™•ç†å™¨"""
        self.stop_event.set()
        
        # ç™¼é€åœæ­¢ä¿¡è™Ÿ
        try:
            self.log_queue.put_nowait(None)
        except queue.Full:
            pass
        
        # ç­‰å¾…å·¥ä½œåŸ·è¡Œç·’çµæŸ
        if self.worker_thread and self.worker_thread.is_alive():
            self.worker_thread.join(timeout=2)
        
        super().close()


def setup_optimized_logger(name: str = 'chatbot', enable_async: bool = True) -> logging.Logger:
    """
    è¨­ç½®å„ªåŒ–çš„æ—¥èªŒè¨˜éŒ„å™¨
    
    Args:
        name: Logger åç¨±
        enable_async: æ˜¯å¦å•Ÿç”¨ç•°æ­¥è™•ç†
        
    Returns:
        å„ªåŒ–çš„ Logger å¯¦ä¾‹
    """
    logger = logging.getLogger(name)
    
    # é¿å…é‡è¤‡è¨­ç½®
    if logger.handlers:
        return logger
    
    logger.setLevel(logging.INFO)
    
    # ğŸ”¥ Console Handler - å½©è‰²è¼¸å‡º
    console_handler = logging.StreamHandler()
    console_formatter = HighPerformanceFormatter(enable_json=False, enable_colors=True)
    console_handler.setFormatter(console_formatter)
    
    # ğŸ”¥ File Handler - JSON æ ¼å¼
    try:
        import os
        os.makedirs('logs', exist_ok=True)
        file_handler = logging.FileHandler('logs/app.log', encoding='utf-8')
        file_formatter = HighPerformanceFormatter(enable_json=True, enable_colors=False)
        file_handler.setFormatter(file_formatter)
    except Exception as e:
        # å¦‚æœæª”æ¡ˆè™•ç†å™¨å‰µå»ºå¤±æ•—ï¼Œåªä½¿ç”¨ console
        base_logger.warning(f"ç„¡æ³•å‰µå»ºæª”æ¡ˆæ—¥èªŒè™•ç†å™¨: {e}")
        file_handler = None
    
    # ä½¿ç”¨ç•°æ­¥è™•ç†å™¨åŒ…è£ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
    if enable_async:
        async_console = AsyncLogHandler(console_handler, queue_size=500)
        logger.addHandler(async_console)
        
        if file_handler:
            async_file = AsyncLogHandler(file_handler, queue_size=1000)
            logger.addHandler(async_file)
    else:
        logger.addHandler(console_handler)
        if file_handler:
            logger.addHandler(async_file)
    
    return logger


class LoggerPerformanceMonitor:
    """æ—¥èªŒæ•ˆèƒ½ç›£æ§å™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        self.log_counts = {
            'DEBUG': 0,
            'INFO': 0,
            'WARNING': 0,
            'ERROR': 0,
            'CRITICAL': 0
        }
        self.total_logs = 0
        self._lock = threading.Lock()
    
    def record_log(self, level: str):
        """è¨˜éŒ„æ—¥èªŒ"""
        with self._lock:
            if level in self.log_counts:
                self.log_counts[level] += 1
            self.total_logs += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """å–å¾—çµ±è¨ˆè³‡è¨Š"""
        uptime = time.time() - self.start_time
        with self._lock:
            return {
                'uptime_seconds': round(uptime, 1),
                'total_logs': self.total_logs,
                'logs_per_second': round(self.total_logs / max(uptime, 1), 2),
                'log_levels': dict(self.log_counts),
                'sensitive_data_filter': OptimizedSensitiveDataFilter.get_cache_stats()
            }


# å…¨åŸŸæ•ˆèƒ½ç›£æ§å™¨
_performance_monitor = LoggerPerformanceMonitor()

def get_logger_stats() -> Dict[str, Any]:
    """å–å¾—æ—¥èªŒç³»çµ±çµ±è¨ˆè³‡è¨Š"""
    return _performance_monitor.get_stats()


# å»ºç«‹å„ªåŒ–çš„é è¨­ logger
optimized_logger = setup_optimized_logger('optimized_chatbot', enable_async=True)

# æä¾›ä¾¿æ·çš„æ—¥èªŒå‡½æ•¸
def log_info(message: str, *args, **kwargs):
    """é«˜æ•ˆèƒ½ INFO æ—¥èªŒ"""
    _performance_monitor.record_log('INFO')
    optimized_logger.info(message, *args, **kwargs)

def log_error(message: str, *args, **kwargs):
    """é«˜æ•ˆèƒ½ ERROR æ—¥èªŒ"""
    _performance_monitor.record_log('ERROR')
    optimized_logger.error(message, *args, **kwargs)

def log_warning(message: str, *args, **kwargs):
    """é«˜æ•ˆèƒ½ WARNING æ—¥èªŒ"""
    _performance_monitor.record_log('WARNING')
    optimized_logger.warning(message, *args, **kwargs)

def log_debug(message: str, *args, **kwargs):
    """é«˜æ•ˆèƒ½ DEBUG æ—¥èªŒ"""
    _performance_monitor.record_log('DEBUG')
    optimized_logger.debug(message, *args, **kwargs)