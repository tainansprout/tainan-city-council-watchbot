"""
é«˜æ•ˆèƒ½æ—¥èªŒç³»çµ±
æ•´åˆåŸå§‹ logger.py å’Œ optimized_logger.py çš„åŠŸèƒ½
åŒ…å«ç•°æ­¥è™•ç†ã€é ç·¨è­¯æ­£å‰‡è¡¨é”å¼æ•æ„Ÿè³‡æ–™éæ¿¾å’Œå„ªåŒ–çš„æ ¼å¼åŒ–å™¨
"""

import os
import logging
import logging.handlers
import json
import re
import copy
import threading
import queue
import time
from datetime import datetime
from typing import Dict, Any, Optional, Pattern, List


class SensitiveDataFilter(logging.Filter):
    """å„ªåŒ–çš„æ•æ„Ÿè³‡æ–™éæ¿¾å™¨ - ä½¿ç”¨é ç·¨è­¯æ­£å‰‡è¡¨é”å¼"""
    
    # ğŸ”¥ é—œéµå„ªåŒ–ï¼šé ç·¨è­¯æ­£å‰‡è¡¨é”å¼
    _COMPILED_PATTERNS: List[Pattern] = [
        re.compile(r'(api_key["\']?\s*[:=]\s*["\']?)([^"\'>\s]+)', re.IGNORECASE),
        re.compile(r'(token["\']?\s*[:=]\s*["\']?)([^"\'>\s]+)', re.IGNORECASE),
        re.compile(r'(password["\']?\s*[:=]\s*["\']?)([^"\'>\s]+)', re.IGNORECASE),
        re.compile(r'(secret["\']?\s*[:=]\s*["\']?)([^"\'>\s]+)', re.IGNORECASE),
        re.compile(r'(Bearer\s+)([A-Za-z0-9\-_]+)', re.IGNORECASE),
        re.compile(r'(Authorization:\s*Bearer\s+)([A-Za-z0-9\-_]+)', re.IGNORECASE),
        # ä¿¡ç”¨å¡è™Ÿç¢¼
        re.compile(r'\b(?:\d{4}[-\s]?){3}\d{4}\b'),
        # é›»è©±è™Ÿç¢¼
        re.compile(r'\b09\d{8}\b'),
        # Email éƒ¨åˆ†é®è”½
        re.compile(r'([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'),
    ]
    
    SENSITIVE_KEYS = {
        'api_key', 'password', 'token', 'secret', 'auth', 'credential',
        'openai_api_key', 'line_channel_access_token', 'line_channel_secret'
    }
    
    # ğŸ”¥ æ€§èƒ½å„ªåŒ–ï¼šå¿«å–å¸¸è¦‹çš„æ¸…ç†çµæœ
    _cache: Dict[str, str] = {}
    _cache_lock = threading.Lock()
    _max_cache_size = 500
    
    def filter(self, record):
        """éæ¿¾æ—¥èªŒè¨˜éŒ„ä¸­çš„æ•æ„Ÿè³‡æ–™"""
        if hasattr(record, 'msg'):
            if isinstance(record.msg, dict):
                record.msg = self._sanitize_dict(record.msg)
            elif isinstance(record.msg, str):
                record.msg = self.sanitize_fast(record.msg)
        return True
    
    @classmethod
    def sanitize_fast(cls, text: str) -> str:
        """
        å¿«é€Ÿæ•æ„Ÿè³‡æ–™æ¸…ç† - ä½¿ç”¨é ç·¨è­¯æ­£å‰‡è¡¨é”å¼
        
        Args:
            text: è¦æ¸…ç†çš„æ–‡æœ¬
            
        Returns:
            æ¸…ç†å¾Œçš„æ–‡æœ¬
        """
        if not text or not isinstance(text, str):
            return str(text)
        
        # ğŸ”¥ å¿«å–æª¢æŸ¥ï¼ˆåªå¿«å–çŸ­æ–‡æœ¬ï¼‰
        if len(text) < 500:
            with cls._cache_lock:
                if text in cls._cache:
                    return cls._cache[text]
        
        # é•·åº¦é™åˆ¶ï¼Œé¿å…è™•ç†è¶…å¤§å­—ä¸²
        if len(text) > 10000:
            text = text[:10000] + "...[truncated]"
        
        # ä½¿ç”¨é ç·¨è­¯æ­£å‰‡å¿«é€Ÿè™•ç†
        sanitized = text
        for pattern in cls._COMPILED_PATTERNS:
            # æ ¹æ“šæ­£å‰‡è¡¨é”å¼çš„ç¾¤çµ„æ•¸é‡æ±ºå®šæ›¿æ›ç­–ç•¥
            if 'api_key' in pattern.pattern or 'token' in pattern.pattern or 'password' in pattern.pattern or 'secret' in pattern.pattern or 'Bearer' in pattern.pattern:
                # é€™äº›æ¨¡å¼æœ‰å…©å€‹æ•ç²ç¾¤çµ„ï¼š(å‰ç¶´)(å€¼)
                sanitized = pattern.sub(r'\1***', sanitized)
            elif pattern.pattern.startswith('([a-zA-Z0-9._%+-]+)@'):  # Email ç‰¹æ®Šè™•ç†
                sanitized = pattern.sub(r'\1***@\2', sanitized)
            else:  # æ²’æœ‰æ•ç²ç¾¤çµ„ï¼Œç›´æ¥æ›¿æ›
                sanitized = pattern.sub('***', sanitized)
        
        # ğŸ”¥ çµæœå¿«å–ï¼ˆæ§åˆ¶å¿«å–å¤§å°ï¼‰
        if len(text) < 500:
            with cls._cache_lock:
                if len(cls._cache) >= cls._max_cache_size:
                    # ç°¡å–®çš„ LRUï¼šæ¸…é™¤ä¸€åŠæœ€èˆŠçš„é …ç›®
                    items = list(cls._cache.items())
                    cls._cache = dict(items[len(items)//2:])
                cls._cache[text] = sanitized
        
        return sanitized
    
    def _sanitize_dict(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ¸…ç†å­—å…¸ä¸­çš„æ•æ„Ÿè³‡æ–™"""
        if not isinstance(data, dict):
            return data
        
        sanitized = {}
        for key, value in data.items():
            if any(sensitive in key.lower() for sensitive in self.SENSITIVE_KEYS):
                sanitized[key] = "***REDACTED***"
            elif isinstance(value, dict):
                sanitized[key] = self._sanitize_dict(value)
            elif isinstance(value, list):
                sanitized[key] = [self._sanitize_dict(item) if isinstance(item, dict) else item for item in value]
            else:
                sanitized[key] = value
        
        return sanitized
    
    def _sanitize_string(self, text: str) -> str:
        """æ¸…ç†å­—ç¬¦ä¸²ä¸­çš„æ•æ„Ÿè³‡æ–™ - å‘å¾Œå…¼å®¹æ–¹æ³•"""
        return self.sanitize_fast(text)
    
    @classmethod
    def get_cache_stats(cls) -> Dict[str, int]:
        """å–å¾—å¿«å–çµ±è¨ˆè³‡è¨Š"""
        with cls._cache_lock:
            return {
                'cache_size': len(cls._cache),
                'max_cache_size': cls._max_cache_size,
                'cache_usage_percent': int((len(cls._cache) / cls._max_cache_size) * 100)
            }
    
    @classmethod
    def clear_cache(cls):
        """æ¸…ç©ºå¿«å–"""
        with cls._cache_lock:
            cls._cache.clear()


class StructuredFormatter(logging.Formatter):
    """é«˜æ•ˆèƒ½çµæ§‹åŒ–æ—¥èªŒæ ¼å¼å™¨"""
    
    def __init__(self, enable_colors: bool = False):
        super().__init__()
        self.enable_colors = enable_colors
        
        # ğŸ”¥ é å»ºç«‹é¡è‰²æ˜ å°„ï¼Œé¿å…é‡è¤‡è¨ˆç®—
        if enable_colors:
            self.color_map = {
                'DEBUG': '\033[36m',    # é’è‰²
                'INFO': '\033[32m',     # ç¶ è‰²  
                'WARNING': '\033[33m',  # é»ƒè‰²
                'ERROR': '\033[31m',    # ç´…è‰²
                'CRITICAL': '\033[35m', # ç´«è‰²
            }
            self.reset_color = '\033[0m'
        
        # ğŸ”¥ é å»ºç«‹æ™‚é–“æ ¼å¼ï¼Œé¿å…é‡è¤‡ strftime èª¿ç”¨
        self._last_time_cache = {}
        self._time_cache_lock = threading.Lock()
    
    def format(self, record):
        """å„ªåŒ–çš„ JSON æ ¼å¼åŒ–"""
        # å¿«é€Ÿæ•æ„Ÿè³‡æ–™æ¸…ç†
        try:
            message = SensitiveDataFilter.sanitize_fast(record.getMessage())
        except Exception:
            message = record.getMessage()
        
        log_entry = {
            'timestamp': self._get_formatted_time(),
            'level': record.levelname,
            'logger': record.name,
            'module': record.module,
            'message': message,
        }
        
        # ğŸ”¥ åªæœ‰éŒ¯èª¤æ™‚æ‰åŠ å…¥é¡å¤–è³‡è¨Šï¼Œæ¸›å°‘ JSON å¤§å°
        if record.levelno >= logging.ERROR:
            log_entry.update({
                'function': record.funcName,
                'line': record.lineno,
            })
        
        # æ·»åŠ ç•°å¸¸è³‡è¨Š
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
        
        # æ·»åŠ é¡å¤–çš„ä¸Šä¸‹æ–‡è³‡è¨Š
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
        
        return json.dumps(log_entry, ensure_ascii=False, separators=(',', ':'))
    
    def _get_formatted_time(self) -> str:
        """å„ªåŒ–çš„æ™‚é–“æ ¼å¼åŒ–"""
        current_time = time.time()
        
        # ä½¿ç”¨ç°¡å–®çš„å¿«å–æ©Ÿåˆ¶ï¼Œå¿«å–åˆ°ç§’ç´šåˆ¥
        cache_key = int(current_time)
        
        with self._time_cache_lock:
            if cache_key in self._last_time_cache:
                return self._last_time_cache[cache_key]
            
            # æ ¼å¼åŒ–æ™‚é–“
            formatted = datetime.fromtimestamp(current_time).isoformat()
            
            # å¿«å–çµæœ
            self._last_time_cache[cache_key] = formatted
            
            # æ¸…ç†èˆŠçš„å¿«å–é …ç›®ï¼ˆä¿ç•™æœ€è¿‘10ç§’ï¼‰
            cutoff = cache_key - 10
            old_keys = [k for k in self._last_time_cache.keys() if k < cutoff]
            for old_key in old_keys:
                del self._last_time_cache[old_key]
            
            return formatted


class ColoredConsoleFormatter(logging.Formatter):
    """å„ªåŒ–çš„å½©è‰²æ§åˆ¶å°æ ¼å¼å™¨"""
    
    LEVEL_COLORS = {
        logging.DEBUG: '\x1b[36m',     # Cyan
        logging.INFO: '\x1b[32m',      # Green
        logging.WARNING: '\x1b[33m',   # Yellow
        logging.ERROR: '\x1b[31m',     # Red
        logging.CRITICAL: '\x1b[35m',  # Magenta
    }
    
    RESET = '\x1b[0m'
    
    def __init__(self, fmt=None, datefmt=None):
        super().__init__(fmt, datefmt)
        # ğŸ”¥ é å»ºç«‹æ™‚é–“æ ¼å¼ï¼Œé¿å…é‡è¤‡ strftime èª¿ç”¨
        self._last_time_cache = {}
        self._time_cache_lock = threading.Lock()
    
    def format(self, record):
        """å„ªåŒ–çš„å½©è‰²æ ¼å¼åŒ–"""
        # å¿«é€Ÿæ•æ„Ÿè³‡æ–™æ¸…ç†
        try:
            message = SensitiveDataFilter.sanitize_fast(record.getMessage())
        except Exception:
            message = record.getMessage()
        
        # å‰µå»º record çš„å‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹ record
        colored_record = copy.copy(record)
        color = self.LEVEL_COLORS.get(colored_record.levelno, '')
        colored_record.levelname = f"{color}{colored_record.levelname}{self.RESET}"
        colored_record.msg = message
        
        timestamp = self._get_formatted_time()
        return f"{timestamp} - {colored_record.name} - {colored_record.levelname} - {message}"
    
    def _get_formatted_time(self) -> str:
        """å„ªåŒ–çš„æ™‚é–“æ ¼å¼åŒ–"""
        current_time = time.time()
        cache_key = int(current_time)
        
        with self._time_cache_lock:
            if cache_key in self._last_time_cache:
                return self._last_time_cache[cache_key]
            
            formatted = datetime.fromtimestamp(current_time).strftime('%Y-%m-%d %H:%M:%S')
            self._last_time_cache[cache_key] = formatted
            
            # æ¸…ç†èˆŠçš„å¿«å–é …ç›®
            cutoff = cache_key - 10
            old_keys = [k for k in self._last_time_cache.keys() if k < cutoff]
            for old_key in old_keys:
                del self._last_time_cache[old_key]
            
            return formatted


class AsyncLogHandler(logging.Handler):
    """ç•°æ­¥æ—¥èªŒè™•ç†å™¨ - é¿å… I/O é˜»å¡"""
    
    def __init__(self, target_handler: logging.Handler, queue_size: int = 1000):
        super().__init__()
        self.target_handler = target_handler
        self.log_queue = queue.Queue(maxsize=queue_size)
        self.worker_thread = None
        self.stop_event = threading.Event()
        self.dropped_logs = 0
        self._start_worker()
    
    def _start_worker(self):
        """å•Ÿå‹•èƒŒæ™¯å·¥ä½œåŸ·è¡Œç·’"""
        def worker():
            while not self.stop_event.is_set():
                try:
                    record = self.log_queue.get(timeout=1)
                    if record is None:  # åœæ­¢ä¿¡è™Ÿ
                        break
                    
                    # ç™¼é€åˆ°ç›®æ¨™è™•ç†å™¨
                    self.target_handler.emit(record)
                    self.log_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    # é¿å…æ—¥èªŒéŒ¯èª¤å½±éŸ¿ä¸»ç¨‹å¼
                    print(f"ç•°æ­¥æ—¥èªŒè™•ç†éŒ¯èª¤: {e}")
        
        self.worker_thread = threading.Thread(target=worker, daemon=True, name='AsyncLogWorker')
        self.worker_thread.start()
    
    def emit(self, record: logging.LogRecord):
        """éé˜»å¡çš„æ—¥èªŒç™¼é€"""
        try:
            # ğŸ”¥ è¤‡è£½ record é¿å…ç·šç¨‹é–“æ•¸æ“šç«¶çˆ­
            record_copy = copy.copy(record)
            self.log_queue.put_nowait(record_copy)
        except queue.Full:
            # ä½‡åˆ—æ»¿æ™‚ä¸Ÿæ£„æ—¥èªŒï¼Œé¿å…é˜»å¡ä¸»ç¨‹å¼
            self.dropped_logs += 1
            # æ¯100å€‹ä¸Ÿæ£„çš„æ—¥èªŒå ±å‘Šä¸€æ¬¡
            if self.dropped_logs % 100 == 0:
                print(f"è­¦å‘Šï¼šå·²ä¸Ÿæ£„ {self.dropped_logs} æ¢æ—¥èªŒè¨Šæ¯")
    
    def get_stats(self) -> Dict[str, int]:
        """å–å¾—çµ±è¨ˆè³‡è¨Š"""
        return {
            'queue_size': self.log_queue.qsize(),
            'dropped_logs': self.dropped_logs,
            'worker_alive': self.worker_thread.is_alive() if self.worker_thread else False
        }
    
    def close(self):
        """é—œé–‰è™•ç†å™¨"""
        self.stop_event.set()
        
        # ç™¼é€åœæ­¢ä¿¡è™Ÿ
        try:
            self.log_queue.put_nowait(None)
        except queue.Full:
            pass
        
        # ç­‰å¾…å·¥ä½œåŸ·è¡Œç·’çµæŸ
        if self.worker_thread and self.worker_thread.is_alive():
            self.worker_thread.join(timeout=2)
        
        super().close()


class LoggerManager:
    """å„ªåŒ–çš„æ—¥èªŒç®¡ç†å™¨"""
    
    def __init__(self, name: str = 'chatbot', config: Optional[Dict[str, Any]] = None, enable_async: bool = True):
        self.name = name
        self.config = config or self._load_default_config()
        self.enable_async = enable_async
        self.logger = None
        self._setup_logger()
    
    def _load_default_config(self) -> Dict[str, Any]:
        """è¼‰å…¥é è¨­é…ç½®"""
        default_config = {
            'level': 'DEBUG',
            'file_path': './logs/chatbot.log',
            'max_bytes': 10 * 1024 * 1024,  # 10MB
            'backup_count': 5,
            'format': 'simple',
            'enable_console': True,
            'enable_file': True,
        }
        
        try:
            from .config import ConfigManager
            config_manager = ConfigManager()
            config = config_manager.get_config()
            
            # å®‰å…¨åœ°åˆä½µé…ç½®
            if config:
                default_config.update({
                    'level': config.get('log_level', default_config['level']),
                    'file_path': config.get('logfile', default_config['file_path']),
                    'format': config.get('log_format', default_config['format']),
                })
        except Exception as e:
            print(f"Warning: Could not load config file, using defaults: {e}")
        
        return default_config
    
    def _setup_logger(self):
        """è¨­å®šå„ªåŒ–çš„æ—¥èªŒè¨˜éŒ„å™¨"""
        self.logger = logging.getLogger(self.name)
        
        # å®‰å…¨åœ°è¨­ç½®æ—¥èªŒç´šåˆ¥
        try:
            level = self.config['level'].upper()
            log_level = getattr(logging, level)
            self.logger.setLevel(log_level)
        except (AttributeError, KeyError):
            self.logger.setLevel(logging.DEBUG)
            print(f"Warning: Invalid log level '{self.config.get('level', 'unknown')}', using DEBUG instead")
        
        # é¿å…é‡è¤‡æ·»åŠ  handler
        if self.logger.handlers:
            return
        
        # æ·»åŠ æ•æ„Ÿè³‡æ–™éæ¿¾å™¨
        sensitive_filter = SensitiveDataFilter()
        
        # æ§åˆ¶å°è™•ç†å™¨
        if self.config.get('enable_console', True):
            console_handler = logging.StreamHandler()
            if self.config.get('format', 'simple') == 'structured':
                console_formatter = StructuredFormatter(enable_colors=True)
            else:
                console_formatter = ColoredConsoleFormatter(
                    fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S'
                )
            console_handler.setFormatter(console_formatter)
            console_handler.addFilter(sensitive_filter)
            
            # ğŸ”¥ ä½¿ç”¨ç•°æ­¥è™•ç†å™¨åŒ…è£ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.enable_async:
                async_console = AsyncLogHandler(console_handler, queue_size=500)
                self.logger.addHandler(async_console)
            else:
                self.logger.addHandler(console_handler)
        
        # æª”æ¡ˆè™•ç†å™¨
        if self.config.get('enable_file', True):
            file_path = self.config.get('file_path', './logs/chatbot.log')
            log_dir = os.path.dirname(file_path)
            os.makedirs(log_dir, exist_ok=True)
            
            file_handler = logging.handlers.RotatingFileHandler(
                file_path,
                maxBytes=self.config.get('max_bytes', 10 * 1024 * 1024),
                backupCount=self.config.get('backup_count', 5),
                encoding='utf-8'
            )
            
            if self.config.get('format', 'simple') == 'structured':
                file_formatter = StructuredFormatter(enable_colors=False)
            else:
                file_formatter = logging.Formatter(
                    fmt='%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S'
                )
            
            file_handler.setFormatter(file_formatter)
            file_handler.addFilter(sensitive_filter)
            
            # ğŸ”¥ ä½¿ç”¨ç•°æ­¥è™•ç†å™¨åŒ…è£ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.enable_async:
                async_file = AsyncLogHandler(file_handler, queue_size=1000)
                self.logger.addHandler(async_file)
            else:
                self.logger.addHandler(file_handler)
    
    def get_logger(self) -> logging.Logger:
        """å–å¾—æ—¥èªŒè¨˜éŒ„å™¨"""
        return self.logger
    
    def log_with_context(self, level: int, msg: str, **context):
        """å¸¶ä¸Šä¸‹æ–‡çš„æ—¥èªŒè¨˜éŒ„"""
        extra = {k: v for k, v in context.items() if k not in ['msg', 'args']}
        self.logger.log(level, msg, extra=extra)
    
    def update_config(self, new_config: Dict[str, Any]):
        """æ›´æ–°é…ç½®"""
        self.config.update(new_config)
        # ç§»é™¤ç¾æœ‰ handlers
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        # é‡æ–°è¨­å®š
        self._setup_logger()
    
    def get_stats(self) -> Dict[str, Any]:
        """å–å¾—æ—¥èªŒç³»çµ±çµ±è¨ˆè³‡è¨Š"""
        stats = {
            'logger_name': self.name,
            'log_level': self.logger.level,
            'handler_count': len(self.logger.handlers),
            'async_enabled': self.enable_async,
            'sensitive_data_filter': SensitiveDataFilter.get_cache_stats()
        }
        
        # æ”¶é›†ç•°æ­¥ handler çµ±è¨ˆ
        async_stats = []
        for handler in self.logger.handlers:
            if isinstance(handler, AsyncLogHandler):
                async_stats.append(handler.get_stats())
        
        if async_stats:
            stats['async_handlers'] = async_stats
        
        return stats


class LoggerPerformanceMonitor:
    """æ—¥èªŒæ•ˆèƒ½ç›£æ§å™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        self.log_counts = {
            'DEBUG': 0,
            'INFO': 0,
            'WARNING': 0,
            'ERROR': 0,
            'CRITICAL': 0
        }
        self.total_logs = 0
        self._lock = threading.Lock()
    
    def record_log(self, level: str):
        """è¨˜éŒ„æ—¥èªŒ"""
        with self._lock:
            if level in self.log_counts:
                self.log_counts[level] += 1
            self.total_logs += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """å–å¾—çµ±è¨ˆè³‡è¨Š"""
        uptime = time.time() - self.start_time
        with self._lock:
            return {
                'uptime_seconds': round(uptime, 1),
                'total_logs': self.total_logs,
                'logs_per_second': round(self.total_logs / max(uptime, 1), 2),
                'log_levels': dict(self.log_counts),
                'sensitive_data_filter': SensitiveDataFilter.get_cache_stats()
            }


# å…¨åŸŸæ—¥èªŒç®¡ç†å™¨å¯¦ä¾‹
_logger_manager = LoggerManager(enable_async=True)
logger = _logger_manager.get_logger()

# å…¨åŸŸæ•ˆèƒ½ç›£æ§å™¨
_performance_monitor = LoggerPerformanceMonitor()


def get_logger(name: str = None) -> logging.Logger:
    """å–å¾—æ—¥èªŒè¨˜éŒ„å™¨"""
    if name:
        return logging.getLogger(name)
    return logger


def setup_optimized_logger(name: str = 'chatbot', enable_async: bool = True) -> logging.Logger:
    """
    è¨­ç½®å„ªåŒ–çš„æ—¥èªŒè¨˜éŒ„å™¨
    
    Args:
        name: Logger åç¨±
        enable_async: æ˜¯å¦å•Ÿç”¨ç•°æ­¥è™•ç†
        
    Returns:
        å„ªåŒ–çš„ Logger å¯¦ä¾‹
    """
    manager = LoggerManager(name=name, enable_async=enable_async)
    return manager.get_logger()


def get_logger_stats() -> Dict[str, Any]:
    """å–å¾—æ—¥èªŒç³»çµ±çµ±è¨ˆè³‡è¨Š"""
    return {
        'performance': _performance_monitor.get_stats(),
        'manager': _logger_manager.get_stats()
    }


def setup_request_logging(app):
    """è¨­å®š Flask è«‹æ±‚æ—¥èªŒ"""
    @app.before_request
    def log_request_info():
        from flask import request
        import uuid
        
        # ç”Ÿæˆè«‹æ±‚ ID
        request_id = str(uuid.uuid4())[:8]
        
        # è¨˜éŒ„è«‹æ±‚è³‡è¨Šï¼ˆæ’é™¤æ•æ„Ÿ headersï¼‰
        safe_headers = {
            k: v for k, v in request.headers.items() 
            if k.lower() not in ['authorization', 'x-line-signature']
        }
        
        # è¨˜éŒ„è«‹æ±‚è³‡è¨Š
        logger.info(
            "Incoming request",
            extra={
                'request_id': request_id,
                'method': request.method,
                'url': request.url,
                'remote_addr': request.remote_addr,
                'headers': safe_headers
            }
        )
    
    @app.after_request
    def log_response_info(response):
        # è¨˜éŒ„å›æ‡‰è³‡è¨Š
        logger.info(
            "Response sent",
            extra={
                'status_code': response.status_code,
                'content_length': response.content_length
            }
        )
        return response


# æä¾›ä¾¿æ·çš„æ—¥èªŒå‡½æ•¸
def log_info(message: str, *args, **kwargs):
    """é«˜æ•ˆèƒ½ INFO æ—¥èªŒ"""
    _performance_monitor.record_log('INFO')
    logger.info(message, *args, **kwargs)


def log_error(message: str, *args, **kwargs):
    """é«˜æ•ˆèƒ½ ERROR æ—¥èªŒ"""
    _performance_monitor.record_log('ERROR')
    logger.error(message, *args, **kwargs)


def log_warning(message: str, *args, **kwargs):
    """é«˜æ•ˆèƒ½ WARNING æ—¥èªŒ"""
    _performance_monitor.record_log('WARNING')
    logger.warning(message, *args, **kwargs)


def log_debug(message: str, *args, **kwargs):
    """é«˜æ•ˆèƒ½ DEBUG æ—¥èªŒ"""
    _performance_monitor.record_log('DEBUG')
    logger.debug(message, *args, **kwargs)


